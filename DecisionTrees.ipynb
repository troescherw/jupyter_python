{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees - Entscheidungsbäume\n",
    "\n",
    "Wir wollen zuerst das Beispiel aus dem Datensatz \"Tennis\" nachvollziehen. Anhand historischer Daten wollen wir vorhersagen, ob ein fiktiver Tennis-Spieler Tennis spielt oder nicht. Als Features fließen dabei die **Witterung**, die **Temperatur**, die **Luftfeuchtigkeit** sowie der **Wind** ein. Die Spalte **TennisGespielt** sagt uns, ob er Tennis gespielt hat (1) oder nicht (0). Wir laden den Datensatz und geben ihn aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url=\"https://raw.githubusercontent.com/troescherw/datasets/master/tennis.csv\"\n",
    "df = pd.read_csv(url, delimiter=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir teilen den Datensatz auf in Prädiktoren (X) und in das Kriterium (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :4]\n",
    "y = df.TennisGespielt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die kategorialen Variablen ersetzen wir durch Dummy-Variablen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erstellen das Modell (Entscheidungsbaum) und trainieren den Baum mit den vorliegenden Daten. Aufgrund der geringen Anzahl an Beobachtungen verzichten wir hier auf die Aufteilung und Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=0, criterion=\"entropy\").fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Entscheidungsbaum](https://github.com/troescherw/images/blob/master/entscheidungsbaum.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem Modell können wir eine Vorhersage durchführen und die Ergebnisse der Vorhersage (prediction) mit den realen Daten vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun die vorhergesagten Daten mit der Realität (den Daten in y) tabellarisch gegenüberstellen. Diese Tabelle nennt man **Confusion Matrix**. In der Diagonalen finden wir die richtig vorhergesagten Klassen (also 0 oder 1). Wir stellen fest, dass unser Modell immer richtig lag! Allerdings ist das nicht wirklich aussagekräftig, da wir mit denselben Daten unser Modell testen, mit denen wir auch unser Modell trainiert haben!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(pred,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entscheidungsbaum mit dem IRIS-Datensatz\n",
    "Wir erstellen einen Entscheidungsbaum mit dem IRIS-Datensatz.\n",
    "\n",
    "Beim Iris Datensatz handelt es sich um einen Datensatz mit 150 Beobachtungen von 4 Features von Schwertlilien. Gemessen wurden dabei jeweils die Breite und die Länge des Kelchblatts (Sepal) sowie des Kronblatts (Petal). Des weiteren ist für jeden Datensatz die Art der Schwertlilie (Setosa, Virginica, Versicolor) angegeben. Für jede Spezies liegen 50 Messungen vor.\n",
    "\n",
    "Wir laden den Datensatz und geben die ersten 5 Zeilen aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url  = \"https://raw.githubusercontent.com/troescherw/datasets/master/iris.csv\"\n",
    "iris = pd.read_csv(url, delimiter=\";\")\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir teilen den Datensatz wieder bzgl. der Features auf: Prädiktoren X und Kriterium y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.iloc[:,:4]\n",
    "y = iris.SpeciesID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir teilen den Datensatz bzgl. der Beobachtungen auf: Einen Datensatz mit 70% der Daten verwenden wir für das Training des Modells, mit den verbleibenden 30% der Daten überprüfen wir die Qualität unseres Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   shuffle=True,\n",
    "                                                   random_state=1,\n",
    "                                                   test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun erstellen wir unseren Entscheidungsbaum mit Hilfe des Train-Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=3,\n",
    "                              criterion=\"entropy\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Entscheidungsbaum](https://github.com/troescherw/images/blob/master/Entscheidungsbaum_iris.PNG?raw=true?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erstellen mit unserem Entscheidungsbaum eine Vorhersage und verwenden hierfür den Test-Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir stellen die Vorhersage (pred) mit der Realiät (y_test) wieder tabellarisch in einer **Confusion Matrix** gegenüber. In dieser Matrix stehen wieder die richtig vorhergesagten Klassen (hier also Versicolor, Verginica oder Versicolor) in der Diagnoalen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_labels = y_test.replace([0,1,2], [\"Setosa\",\"Versicolor\",\"Virginica\"])\n",
    "pred_labels = pd.Series(pred).replace([0,1,2], [\"Setosa\",\"Versicolor\",\"Virginica\"])\n",
    "\n",
    "pd.crosstab(pred_labels, ytest_labels.values,\n",
    "           rownames=[\"Predicted\"],\n",
    "           colnames=[\"Reference\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie \"gut\" ist nun unser Modell? In der Diagonale stehen wieder die richtig vorhergesagten Spezies. Insgesamt wurden also 14 + 17 + 12 = 43 Spezies richtig vorhergesagt. Bei 2 Vorhersagen versagte unser Modell: Statt Versicolor wurde eine Virginica, statt eine Virginica wurde eine Versicolor vorhergesagt. In 43 von 45 Fällen lag das Modell aber richtig, das entspricht 96%. Dieser Wert wird **Accuracy** genannt.\n",
    "\n",
    "Mit Hilfe der Funktion *classification_report* können wir neben der Accuracy auch noch weitere Kennzahl ausgeben, die im zugehörigen Skript ausführlich erläutert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung mit Hilfe der PCA\n",
    "Wir wollen nun die IRS-Daten noch visualisieren. Problem: Wir haben 4 Features, die die Spezies bestimmen. Somit müssten wir 4 Dimensionen plotten, was natürlich nicht möglich ist.\n",
    "\n",
    "Hier hilft die **PCA**, die **Principal Component Analysis** (Hauptkomponentenanalyse). Mit Hilfe von mathematischen Verfahren, auf die wir hier nicht näher eingehen werden, reduziert die PCA die Anzahl der Dimensionen, indem durch Linearkombination mehrere Vektoren zu jeweils einem Vektor (der Hauptkomponente) zusammengefasst werden.\n",
    "\n",
    "Um das Vorgehen zu verdeutlichen, laden wir (nochmal) den IRIS-Datensatz. Die Labels laden wir gesondert in die Variable gleichen Namens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/troescherw/datasets/master/iris.csv\"\n",
    "iris = pd.read_csv(url, delimiter=\";\", usecols=[0,1,2,3])\n",
    "labels = pd.read_csv(url, delimiter=\";\", usecols=[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine PCA durchzuführen, sollten die Werte immer standardisiert werden, damit kein Feature über- oder untergewichtet in die Berechnung eingeht. Wir erledigen dies mit Hilfe von *StandardScaler*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "iris_scaled = StandardScaler().fit_transform(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir die PCA durchführen. Wir können hier einen 3D-Plot erstellen, deshalb reduzieren wir die 4 Dimensionen auf 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "iris_pca = PCA(n_components=3).fit_transform(iris_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir diese 3 Features in einem 3D-Plot visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=[15,10])\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "iris_pca = PCA(n_components=3).fit_transform(iris_scaled)\n",
    "for species in labels.Species.unique():\n",
    "    ax.scatter( iris_pca[labels.Species==species][:,0], \n",
    "                iris_pca[labels.Species==species][:,1],\n",
    "                iris_pca[labels.Species==species][:,2],\n",
    "                s=50,\n",
    "                label=species)\n",
    "plt.title(\"IRIS\")\n",
    "plt.legend()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
