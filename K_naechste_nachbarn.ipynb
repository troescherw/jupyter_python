{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nächste Nachbarn (K-nearest Neighbors)\n",
    "Wir wenden den K-nächste-Nachbarn-Algorithmus auf den IRIS-Datensatz an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir laden den Datensatz\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/troescherw/datasets/master/iris.csv\"\n",
    "iris = pd.read_csv(url, delimiter=\";\")\n",
    "iris\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen in X und y\n",
    "X = iris.iloc[:, :4]\n",
    "y = iris.SpeciesID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen in Trainings- und Testdaten\n",
    "# \"Training\" bedeutet hier das Erstellen einer Abstandsmatrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erstellen das Modell und verwenden für k den Wert 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir klassifizieren die Objekte aus dem Test-Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir stellen das Ergebnis in einer Confusion Matrix dar und berechnen die Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "classes = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
    "_=plot_confusion_matrix(knn, X_test, y_test, display_labels=classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimierung des Algorithmus\n",
    "\n",
    "Für die Zuordnung des Objektes zu einer Klasse gibt es mehrere Möglichkeiten: Im einfachsten Fall wird wie schon erwähnt eine schlichte Mehrheitsentscheidung getroffen, was aber nicht immer das beste Ergebnis liefert, insbesondere wenn sich ähnlich oder sogar gleich viele Objekte der jeweiligen Klasse in unmittelbarer Nachbarschaft befinden. Daher kann man altnernativ die Objekte in der Nachbarschaft gewichten: Je näher ein Objekt, desto mehr \"Gewicht\" erhält die jeweilige Klasse.\n",
    "\n",
    "Dem Konstruktor der Klasse *KNeighborsClassifier* kann man deshalb noch das Attribut *weights* bestimmen. Standardmäßig ist dies auf *uniform* gesetzt, was der ersten, einfachen Methode entspricht. Man kann es aber auch auf den Wert *distance* setzen, dann werden die Abstände gewichtet.\n",
    "\n",
    "Im folgenden Skript wollen wir nun anhand eines Datensatzes das optimale K und auch die optimale Gewichtung der Abstände bestimmen. Wir verwenden hierfür einen Datensatz aus dem *sklearn*-Package, der über chemische Analysedaten von Weinen verfügt. Jeder der 178 Weine stammt von einem von drei italienischen Winzern (\"cultivator\"). Wie gut kann unser Modell vorhersagen, von welchem Winzer der Wein stammt?\n",
    "\n",
    "Um unser Modell zu optimieren werden wir ein K von 1 bis 10 verwenden und für jedes K ein unterschiedliches Verfahren für die Gewichtung verwenden. Es werden also insgesamt 20 Modelle durchprobiert und für jedes ermitteln wir die Accuracy. Die Kombination aus K und dem Typ für die Gewichtung mit der höchsten Accuracy liefert (vermutlich) die besten Hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des Datensatzes\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wines = load_wine()\n",
    "print(wines.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilen in Trainings- und Testdaten\n",
    "# \"Training\" bedeutet hier das Erstellen einer Abstandsmatrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines.data, wines.target, shuffle=True, test_size=0.3, random_state=23 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "weights = [\"uniform\", \"distance\"]\n",
    "ks = np.arange(1,11)\n",
    "\n",
    "   \n",
    "for weight in weights:\n",
    "    for k in ks:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights=weight).fit(X_train, y_train)\n",
    "        print(f\"K={k}, weights={weight}, Accuracy = {knn.score(X_test, y_test):.3}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN für Regressionsanalyse\n",
    "KNN kann auch für Regression verwendet werden. Im Beispiel werden Mietpreise für Wohnungen vorherhergesagt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Mietpreise\n",
    "X = np.array([\n",
    "        [69, 1685],\n",
    "        [28, 625],\n",
    "        [42, 524],\n",
    "        [113, 2100],\n",
    "        [54, 1200],\n",
    "        [43, 750],\n",
    "        [62, 1178],\n",
    "        [24, 900],\n",
    "        [33, 715],\n",
    "        [92, 2915],\n",
    "        [53, 1440]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=3).fit(X[:,0].reshape(-1,1), X[:,1].reshape(-1,1))\n",
    "\n",
    "# Predictions\n",
    "qm = np.array([50,70,90]).reshape(-1,1)\n",
    "print(knn.predict(qm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.scatter(X[:,0], X[:,1], label=\"Trainingsdaten\")\n",
    "plt.scatter(qm, knn.predict(qm), label=\"Vorhersagen\")\n",
    "plt.legend()\n",
    "plt.title(\"Mietpreise Wohnungen mit KNN\")\n",
    "plt.xlabel(r\"Größe der Wohnung in $m^2$\")\n",
    "plt.ylabel(\"Mietpreis in €\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
