{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd509ff",
   "metadata": {},
   "source": [
    "# Modellevaluierung und Grid Search\n",
    "## K-Fold-Cross Validation\n",
    "\n",
    "Bisher haben wir einen Datensatz in einen Trainings- und einen Testdatensatz aufgeteilt. Doch es besteht die Möglichkeit, dass wir einen \"ungünstigen\" Trainings- bzw. Testdatensatz erhalten! Außerdem wissen wir nicht, wie \"stabil\" unser Modell ist. Schießlich wollen wir auch noch die Hyperparameter optimieren, also Parameter, die wir *vor* dem Trainieren unseres Modells bestimmen müssen. Um diese Hyperparameter zu optimieren und jeweils die Qualität des Modells zu bestimmen verwenden man häufig die sog. K-Fold-Cross-Validation.\n",
    "\n",
    "Im diesem Beispiel wollen wir die handschriftlich erstellten Ziffern erkennen und verwenden hierfür den K-Nearest-Neighbors-Klassifizierer. Dem Konstruktor der Klasse *KNeighborsClassifier* können wir 2 Hyperparameter als Argumente übergeben:\n",
    "\n",
    "- n_neighbors: Entspricht dem \"K\" in K-Nearest-Neighbors\n",
    "- weights: *uniform* oder *distance*, bei *uniform* werden die Distanzen nicht gewichtet, bei *distance* werden sie gewichtet\n",
    "\n",
    "## Grid Search\n",
    "Um die besten Hyperparameter zu bestimmen, gehen wir nun wie folgt vor:\n",
    "\n",
    "- Wir erstellen ein Dictionary mit diesen Parametern. Für K versuchen wir die Werte 1, 3, 5, 7, 9 und 11\n",
    "- Für jedes dieser Kombinationen, also insgesamt 2 * 6 = 12 Kombinationen, werden Modelle erstellt\n",
    "- Wir führen mit K-Fold-Cross-Validation jeweils ein Modell. Da wir im Beispiel 5 Fold erstellen, werden also jeweils 5 Modelle für jedes der Kombinationen erstellt (also 5 * 12 = 60).\n",
    "- Für jede Kombination wird jeweils der Mittelwert des Scores besimmt (hier die Accuracy).\n",
    "- Das Objekt der Klasse GridSearchCV kann uns nun die Parameter zurückgeben, die die beste durchschnittliche Accuracy lieferte.\n",
    "- Als letztes erstellen wir ein Objekt der Klasse *KNeighborsClassifier*, trainieren das Modell mit dem Test-Datensatz und testen mit dem ursprünglich erstellen Testdaten. **Wichtig**: Diese Testdaten wurden nicht bei der Cross-Validation verwendet! Das Modell sieht diese Testdaten also zum ersten Mal!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Aufteilen in Test- und Trainingsdaten. Die Testdaten werden für die abschließende\n",
    "# Evaluation verwendet (nicht bei der Cross-Validation!). Wir halten uns dafür\n",
    "# 20% der Daten zurück.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=42, test_size=0.2)\n",
    "\n",
    "# Wir definieren die Hyperparameter, die wir testen wollen, insgesamt also 12 Modelle!\n",
    "# Die Keys im Dictionary müssen exakt den Argumenten der jeweiligen Klasse lauten!\n",
    "parameter_grid = {\"weights\" : [\"uniform\", \"distance\"],\n",
    "                 \"n_neighbors\" : [1, 3, 5, 7, 9, 11]}\n",
    "\n",
    "\n",
    "# Wir erstellen ein Objekt der Klasse GridSearchCV, übergeben ein Objekt der Klasse KNeighborsClassifier,\n",
    "# unser Grid mit den Hyperparametern, für das Scoring definieren wir die Accuracy,\n",
    "# wir bestimmen mit cv=5 dass wir 5 Folds erstellen wollen (K-Folds).\n",
    "# \"Verbose=3\" bestimmt, dass wir einige Ausgaben während des Trainings erhalten,\n",
    "# \"n_jobs=-1\" bestimmt, dass wir alle Prozessoren für Threads nutzen wollen.\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), parameter_grid, scoring=\"accuracy\", cv=5, verbose = 3, n_jobs=-1) \n",
    "\n",
    "# Nun trainieren wir insgesamt 60 Modelle (2 * 6 * 5)\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir können nun die Parameter ausgeben, die die beste Performance lieferten:\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ef2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir können nun mit den bisher unverwendeten Testdaten ein Modell erstellen und\n",
    "# das Modell evaluieren. Die Methode predict verwendet das beste gefundene Modell!\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41eafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schließlich können wir auch noch eine Confusion Matrix ausgeben\n",
    "plot_confusion_matrix(grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b53d75e",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV\n",
    "Wir haben für den Hyperparameter *K* bei K-Nearest-Neighbors vorab definierte K´s vorgegeben (1, 3, 5, 7, 9, und 11). Wir können aber auch zufällig aus einer Range definierte Werte für K Modelle trainieren. Vielleicht ist ja ein *K* das \"beste\" K, das wir vorab gar nicht in Betracht ziehen!? Die Klasse *RandomizedSearchCV* wählt zufällige Kombinationen aller vorgegebenen Parameter aus und führt schließlich wieder mit jedes dieser Kombinationen eine K-Fold-Cross-Validation aus.\n",
    "\n",
    "Statt der vorgegebenen Liste für die K´s wird hier also eine Bereich definiert, im Beispiel Werte für K von 1 bis 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7efa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameter_grid = {\"weights\" : [\"uniform\", \"distance\"],\n",
    "                 \"n_neighbors\" : range(1,13)}\n",
    "\n",
    "rgrid = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=parameter_grid, n_iter=10, scoring=\"accuracy\", n_jobs=-1,\n",
    "                          verbose=3)\n",
    "\n",
    "rgrid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgrid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
