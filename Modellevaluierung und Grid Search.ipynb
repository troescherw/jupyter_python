{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb648bdd",
   "metadata": {},
   "source": [
    "# Modellevaluierung und Grid Search\n",
    "## K-Fold-Cross Validation\n",
    "\n",
    "Bisher haben wir einen Datensatz in einen Trainings- und einen Testdatensatz aufgeteilt. Doch es besteht die Möglichkeit, dass wir einen \"ungünstigen\" Trainings- bzw. Testdatensatz erhalten! Außerdem wissen wir nicht, wie \"stabil\" unser Modell ist. Schießlich wollen wir auch noch die Hyperparameter optimieren, also Parameter, die wir *vor* dem Trainieren unseres Modells bestimmen müssen. Um diese Hyperparameter zu optimieren und jeweils die Qualität des Modells zu bestimmen verwenden man häufig die sog. K-Fold-Cross-Validation.\n",
    "\n",
    "Im diesem Beispiel wollen wir die handschriftlich erstellten Ziffern erkennen und verwenden hierfür den K-Nearest-Neighbors-Klassifizierer. Dem Konstruktor der Klasse *KNeighborsClassifier* können wir 2 Hyperparameter als Argumente übergeben:\n",
    "\n",
    "- n_neighbors: Entspricht dem \"K\" in K-Nearest-Neighbors\n",
    "- weights: *uniform* oder *distance*, bei *uniform* werden die Distanzen nicht gewichtet, bei *distance* werden sie gewichtet\n",
    "\n",
    "## Grid Search\n",
    "Um die besten Hyperparameter zu bestimmen, gehen wir nun wie folgt vor:\n",
    "\n",
    "- Wir erstellen ein Dictionary mit diesen Parametern. Für K versuchen wir die Werte 1, 3, 5, 7, 9 und 11\n",
    "- Für jedes dieser Kombinationen, also insgesamt 2 * 6 = 12 Kombinationen, werden Modelle erstellt\n",
    "- Wir führen mit K-Fold-Cross-Validation jeweils ein Modell. Da wir im Beispiel 5 Fold erstellen, werden also jeweils 5 Modelle für jedes der Kombinationen erstellt (also 5 * 12 = 60).\n",
    "- Für jede Kombination wird jeweils der Mittelwert des Scores besimmt (hier die Accuracy).\n",
    "- Das Objekt der Klasse GridSearchCV kann uns nun die Parameter zurückgeben, die die beste durchschnittliche Accuracy lieferte.\n",
    "- Als letztes erstellen wir ein Objekt der Klasse *KNeighborsClassifier*, trainieren das Modell mit dem Test-Datensatz und testen mit dem ursprünglich erstellen Testdaten. **Wichtig**: Diese Testdaten wurden nicht bei der Cross-Validation verwendet! Das Modell sieht diese Testdaten also zum ersten Mal!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18878cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Aufteilen in Test- und Trainingsdaten. Die Testdaten werden für die abschließende\n",
    "# Evaluation verwendet (nicht bei der Cross-Validation!). Wir halten uns dafür\n",
    "# 20% der Daten zurück.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=42, test_size=0.2)\n",
    "\n",
    "# Wir definieren die Hyperparameter, die wir testen wollen, insgesamt also 12 Modelle!\n",
    "# Die Keys im Dictionary müssen exakt den Argumenten der jeweiligen Klasse lauten!\n",
    "parameter_grid = {\"weights\" : [\"uniform\", \"distance\"],\n",
    "                 \"n_neighbors\" : [1, 3, 5, 7, 9, 11]}\n",
    "\n",
    "\n",
    "# Wir erstellen ein Objekt der Klasse GridSearchCV, übergeben ein Objekt der Klasse KNeighborsClassifier,\n",
    "# unser Grid mit den Hyperparametern, für das Scoring definieren wir die Accuracy,\n",
    "# wir bestimmen mit cv=5 dass wir 5 Folds erstellen wollen (K-Folds).\n",
    "# \"Verbose=3\" bestimmt, dass wir einige Ausgaben während des Trainings erhalten,\n",
    "# \"n_jobs=-1\" bestimmt, dass wir alle Prozessoren für Threads nutzen wollen.\n",
    "\n",
    "# Nun trainieren wir insgesamt 60 Modelle (2 * 6 * 5)\n",
    "grid = GridSearchCV(KNeighborsClassifier(), parameter_grid, scoring=\"accuracy\", cv=5, verbose = 3, n_jobs=-1) \n",
    "\n",
    "# Nun trainieren wir insgesamt 60 Modelle (2 * 6 * 5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Wir können nun die Parameter ausgeben, die die beste Performance lieferten:\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir können nun mit den bisher unverwendeten Testdaten das Modell evaluieren.\n",
    "# Die Methode predict verwendet das beste gefundene Modell!\n",
    "\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75e72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schließlich können wir auch noch eine Confusion Matrix ausgeben\n",
    "plot_confusion_matrix(grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf540e",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV\n",
    "Wir haben für den Hyperparameter *K* bei K-Nearest-Neighbors vorab definierte K´s vorgegeben (1, 3, 5, 7, 9, und 11). Wir können aber auch zufällig aus einer Range definierte Werte für K Modelle trainieren. Vielleicht ist ja ein *K* das \"beste\" K, das wir vorab gar nicht in Betracht ziehen!? Die Klasse *RandomizedSearchCV* wählt zufällige Kombinationen aller vorgegebenen Parameter aus und führt schließlich wieder mit jedes dieser Kombinationen eine K-Fold-Cross-Validation aus.\n",
    "\n",
    "Statt der vorgegebenen Liste für die K´s wird hier also eine Bereich definiert, im Beispiel Werte für K von 1 bis 12.\n",
    "\n",
    "*Hinweis:* Im gegebenen Beispiel macht die Verwendung eines *RandomizedSearchCV* wenig Sinn, da wir nur wenige Parameter verwenden. Je mehr Parameter ein Modell verwendet, insbesondere wenn diese *float*-Werte enthalten, desto sinnvoller ist der Einsatz eines *RandomizedSearchCV*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce09625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameter_grid = {\"weights\" : [\"uniform\", \"distance\"],\n",
    "                 \"n_neighbors\" : range(1,13)}\n",
    "\n",
    "rgrid = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=parameter_grid, n_iter=10, \n",
    "                           scoring=\"accuracy\", n_jobs=-1, cv=10, verbose=3)\n",
    "\n",
    "rgrid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgrid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231319e6",
   "metadata": {},
   "source": [
    "## Daten standardisieren / normieren\n",
    "Vielleicht ist es jemandem aufgefallen: Wir haben den Klassifikator K-Nearest-Neighbors verwendet. Wir haben bereits gelernt, dass man u.a. bei Machine-Learning-Modellen, die mit Abstandsberechnungen arbeiten, die Daten vorher skalieren sollte.\n",
    "\n",
    "Nun haben wir aber ein kleines Problem: Die Standardisierung der Daten muss für jeden Fold für sich berechnet werden, schließlich verfügt jedes Fold über einen Mittelwert und Standardabweichung (bzw. jeweils eigene Minima und Maxima, sollte man den Min-Max-Scaler verwenden). Wie können wir nun die Daten für jeden Fold für sich standardardisieren?\n",
    "\n",
    "Hier hilft uns **Pipelining** weiter: Wir definieren in einer Pipeline eine Folge von Preprocessing-Schritten, der letzte Schritt enthält die *fit*-Methode für das Erstellen des jeweiligen Modells. Hier möchten wir also **vor** dem Aufruf der *fit*-Methode die Daten skalieren, hier mit Hilfe der Standardskalierung (Z-Werte).\n",
    "\n",
    "Dazu erstellen wir ein Objekt der Klasse *Pipeline* und übergeben ein Dictionary. Jedem Schlüssel weisen wir einen beliebigen String als Key zu, im Beispiel *scaler* und *kn* (für \"K-Neighbors\").\n",
    "\n",
    "Anschließßend führen wir den Grid-Search durch und übergeben die jeweiligen Parameter. Den Parametern wird jeweils der Key aus dem Dictionary, gefolgt durch zwei Underscores vorangestellt. Dadurch kann GridSearch den jeweiligen Parameter korrekt zuordnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([( \"scaler\" , StandardScaler()),\n",
    "                       (\"kn\",KNeighborsClassifier())])\n",
    "\n",
    "parameter_grid = {\"kn__weights\" : [\"uniform\", \"distance\"],\n",
    "                 \"kn__n_neighbors\" : [1, 3, 5, 7, 9, 11]}\n",
    "\n",
    "\n",
    "\n",
    "rgrid = GridSearchCV(pipeline, parameter_grid, cv=10)\n",
    "rgrid.fit(X_train, y_train)\n",
    "\n",
    "print(rgrid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37dba00",
   "metadata": {},
   "source": [
    "## Beispiel: Breast-Cancer-Datensatz mit Random Forest Classifier\n",
    "Als abschließendes Beispiel wollen wir nochmals den Breast-Cancer-Datensatz aus sklearn verwenden, um eine Klassifizierung bösartig (malign) und gutartib (benign) vorzunehmen.\n",
    "\n",
    "Der RandomForestClassifier bietet viele Hyperparameter, wir wollen folgende optimieren:\n",
    "\n",
    "* n_estimators (Anzahl der Bäume)\n",
    "* criterion (Maß für die \"Pureness\" eines Baumes, Gini oder Entropy)\n",
    "* max_depth: Maximale Höhe der Bäume\n",
    "* min_samples_split: Minimale Anzahl der Beobachtungen, die für einen weiteren Split benötigt werden\n",
    "* max_features: Anzahl der (zufällig ausgewählten) Features.\n",
    "\n",
    "Wir erstellen jeweils 10 Folds. Bei einem Decision Tree und somit auch bei einem Random Forest ist eine Standardisierung meist nicht notwendig. Das dauert etwas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df8001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "\n",
    "params  = {\"n_estimators\" : [5, 10, 30, 50, 100],\n",
    "           \"criterion\": [\"gini\", \"entropy\"],\n",
    "           \"max_depth\": [3,5,7,8,10],\n",
    "           \"min_samples_split\": [2,3,5,7,11],\n",
    "           \"max_features\": [\"auto\", \"sqrt\", \"log2\"]}\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=42, test_size=0.25)\n",
    "\n",
    "model_cv = GridSearchCV(RandomForestClassifier(), param_grid=params, verbose=True, cv=10, n_jobs=-1)\n",
    "model_cv.fit(X_train, y_train)\n",
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709b15f",
   "metadata": {},
   "source": [
    "Nun erstellen wir wieder mit dem \"besten\" Modell mit den bisher nicht verwendeten Testdaten eine Prognose und evaluieren das Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_cv.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0866c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_cv, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
